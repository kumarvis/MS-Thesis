In this thesis we have presented how the different sensor data can be fused in a complementary fashion to overcome the each other drawbacks. Data fusion techniques have been extensively employed on multi-sensor environments with the aim of fusing and aggregating data from different sensor. In a given context data fusion leads to less expensive, higher quality and more relevant information. We consider a computer vision and machine learning based task to show case the sensor fusion methodologies. We have addressed localization problem by fusing image and \gps sensors and also demonstrated how machine learning and multi-sensor data fusion techniques are critical to the system success.\\

\textbf{Accurate Localization by Fusing Images and GPS Signals:} Localization by fusing the image and \gps sensor has out perform the localization process by using image or \gps sensor alone. We improved the visual localization using the \gps and overcome the problems like occlusion and perceptual aliasing. Then we used image retrieval to reduce the noise in \gps signal.

Problem of visual localization was framed as image retrieval problem and by fusing \gps with vision we filtered out the useful set of features for each training image. Noise in commercial \gps receivers is another problem for short distance visual localization. Noise in \gps impact the labeling of the images. To overcome this problem we demonstrated a vision based solution which gives use more robust and consistent \gps signal as end result. Finally we integrated both of them and performed the experiments to show the various
aspects of method and improvement in localization.

\textbf{Future Work:}
Localization is one of the very critical problem in computer vision. One can build numerous solution over it. In future work we will be focusing on a computer vision based solution for heritage sites {\em i.e} ``Storytelling for Heritage Sites on Smart Phones''. We want to replicate virtual tourist guide functionality in a mobile phone application which adapts the story according to every user
movement and location on the heritage site. Various other sensors like accelerometer, gyroscope scope can be used to predict the user current location with high precision. Integrating social network data
is other interesting extension that could add to the story telling application. Social footprint of people could be stored in form of friendship graphs; choices of every friend
visiting the same site in past, the time he spent at each site etc. could assist application to suggest near by sites to current user.\\

 
\textbf{Modeling User Activity for Conserving Power on Smartphones:}
We have presented a novel approach to schedule Wi-Fi(can be extend to 3G or any other service on smartphones). Using Wi-Fi as an example, we show that intelligent scheduling based on a
user’s activity level leads to lower power consumption without adversely affecting the user experience. Data from various sensors is used to model and predict a user’s activity, which is then used to schedule the wireless services. Running the machine learning algorithms on the embedded devices is a challenging job. Implementation should be very efficient in terms of CPU power consumption and speed to provide an smooth user experience.

\textbf{Future Work:} One can expand this work to come up with an intelligent and automatic profile switcher. With the help of this intelligent profiler smartphone will be able to handle the situations like:

\begin{enumerate}
\item Putting the mobile in silent mode as in your enter in a meeting.
\item Respond to calls when your are driving.
\item Automatic switching between Wi-Fi and data network.
\end{enumerate}

Above we have stated few use cases of our work but the possibilities are endless. Using machine learning we can give ability to machine perceive the world as humans.
